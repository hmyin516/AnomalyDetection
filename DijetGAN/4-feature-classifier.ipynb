{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3612jvsc74a57bd08cfa128f4fb11395d49e92fdd198d725c58b8d3ed6ebf6f1277996a897e1bb89",
   "display_name": "Python 3.6.12 64-bit ('tensorflow-gpu': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE_DIM = 128 # 64 in Gitlab\n",
    "TESTING= False\n",
    "BATCH_SIZE = 64\n",
    "SAMPLE_SIZE= 50000\n",
    "BINS = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = {\n",
    "    \"herwig\": \"../GAN-data/events_anomalydetection_DelphesHerwig_qcd_features.h5\",\n",
    "    \"pythiabg\": \"../GAN-data/events_anomalydetection_DelphesPythia8_v2_qcd_features.h5\",\n",
    "    \"pythiasig\": \"../GAN-data/events_anomalydetection_DelphesPythia8_v2_Wprime_features.h5\"\n",
    "}\n",
    "\n",
    "datatypes = [\"herwig\", \"pythiabg\", \"pythiasig\"]\n",
    "\n",
    "train_features = [\"ptj1\", \"etaj1\", \"mj1\", \"ptj2\", \"etaj2\", \"phij2\", \"mj2\", \"tau21j1\", \"tau21j2\"]\n",
    "condition_features = [\"mjj\"]\n",
    "\n",
    "features = train_features + condition_features\n",
    "GEN_DIM = NOISE_DIM + len(condition_features)\n",
    "DISC_DIM = len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "def cut_data(uncut_data, pTmin = 1200, etamax = 2.5):\n",
    "    # Column 0: ptj1\n",
    "    # Column 1: etaj1\n",
    "    # Column 3: ptj2\n",
    "    # Column 4: etaj2\n",
    "    return uncut_data[((uncut_data[:,0] > pTmin) & (np.abs(uncut_data[:,1]) < etamax)) | ((uncut_data[:,3] > pTmin) & (np.abs(uncut_data[:,4]) < etamax))]\n",
    "\n",
    "np_bg_SB = np.load('..\\data\\processed\\\\np_bg_SB_2.npy')\n",
    "np_bg_SR = np.load('..\\data\\processed\\\\np_bg_SR_2.npy')\n",
    "np_sig_SR = np.load('..\\data\\processed\\\\np_sig_SR_2.npy')\n",
    "\n",
    "np_sig_SR_labeled = np.copy(np_sig_SR)\n",
    "np_bg_SR_labeled = np.copy(np_bg_SR)\n",
    "\n",
    "np_sig_SR_labeled = np.append(np_sig_SR_labeled,np.ones([len(np_sig_SR),1]),1)\n",
    "np_bg_SR_labeled = np.append(np_bg_SR_labeled,np.zeros([len(np_bg_SR),1]),1)\n",
    "np_combined_SR = np.concatenate((np_bg_SR, np_sig_SR), axis = 0)\n",
    "np_combined_SR_labeled = np.concatenate((np_sig_SR_labeled,np_bg_SR_labeled),axis=0)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6205640442400567"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "np_sig_SR.shape[0]/np_bg_SR.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "gen_model = tf.keras.models.load_model('..\\Results\\cdijetgan\\saverun4\\models\\epoch1000-generator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gan(generator, realdata):\n",
    "\n",
    "\n",
    "    labels = sample_fake(refdata = realdata, size = SAMPLE_SIZE) # Sample mjj from the existing distribution of mjj for comparison\n",
    "    labels_scaled = scaler_mjj.transform(labels.reshape(-1,1))\n",
    "    \n",
    "    fakedata_uncut_unscaled = generator(tf.concat([tf.random.uniform((SAMPLE_SIZE, NOISE_DIM)), labels_scaled], 1), training=False)\n",
    "    fakedata_uncut = np.concatenate((scaler.inverse_transform(fakedata_uncut_unscaled), labels.reshape(-1,1)), axis = 1)\n",
    "   \n",
    "\n",
    "    # At least one jet has pT > 1200 and |eta| < 2.5\n",
    "    fakedata = cut_data(fakedata_uncut)\n",
    "\n",
    "    # mjj = sqrt(Ejj**2 - pxjj**2 - pyjj**2 - pzjj**2)\n",
    "    fakedata_mjj = mjj(fakedata)\n",
    "\n",
    "    return fakedata\n",
    "def mjj(output):\n",
    "    pt1 = output[:,0]\n",
    "    eta1 = output[:,1]\n",
    "    m1 = output[:,2]\n",
    "    pt2 = output[:,3]\n",
    "    eta2 = output[:,4]\n",
    "    phi2 = output[:,5]\n",
    "    m2 = output[:,6]\n",
    "    ejj = np.sqrt((pt1 * np.cosh(eta1))**2 + m1**2) + np.sqrt((pt2 * np.cosh(eta2))**2 + m2**2)\n",
    "    pxjj = pt1 + pt2 * np.cos(phi2)\n",
    "    pyjj = pt2 * np.sin(phi2)\n",
    "    pzjj = pt1 * np.sinh(eta1) + pt2 * np.sinh(eta2)\n",
    "    return np.sqrt(ejj**2 - pxjj**2 - pyjj**2 - pzjj**2)\n",
    "def sample_fake(refdata = np_bg_SR, size = BATCH_SIZE):\n",
    "    rand_idx = np.random.choice(refdata.shape[0], size = size)\n",
    "    return refdata[rand_idx, -1].reshape((-1,1))\n",
    "def sample_data(refdata = np_combined_SR_labeled,size= 10000):\n",
    "    rand_idx = np.random.choice(refdata.shape[0], size)\n",
    "    return refdata[rand_idx, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = sample_data(size=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_bg_SB_trimmed = np.delete(np_bg_SB, [i for i in range(np_bg_SB.shape[0] % (BATCH_SIZE * 4))], axis = 0)\n",
    "\n",
    "# Normalize inputs between -1 and 1, mjj between 0 and 1\n",
    "scaler = MinMaxScaler((-1,1)).fit(np_bg_SB_trimmed[:,:-1])\n",
    "scaler_mjj = MinMaxScaler((0,1)).fit(np_bg_SB_trimmed[:,-1].reshape(-1,1))\n",
    "np_bg_SB_scaled = np.concatenate((scaler.transform(np_bg_SB_trimmed[:,:-1]), scaler_mjj.transform(np_bg_SB_trimmed[:,-1].reshape(-1,1))), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data = generate_gan(gen_model,np_combined_SR)\n",
    "generated_data2 = generate_gan(gen_model,np_combined_SR)\n",
    "generated_data = np.concatenate((generated_data,generated_data2), axis = 0)\n",
    "generated_data_labeled  = np.copy(generated_data)\n",
    "generated_data_labeled = np.append(generated_data_labeled,np.zeros([len(generated_data_labeled),1]),1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_bg_SR_labeled  = np.copy(np_bg_SR)\n",
    "np_bg_SR_labeled  = np.append(np_bg_SR_labeled ,np.zeros([len(np_bg_SR_labeled) ,1]),1)\n",
    "np_sig_SR_labeled  = np.copy(np_sig_SR)\n",
    "np_sig_SR_labeled  = np.append(np_sig_SR_labeled ,np.ones([len(np_sig_SR_labeled) ,1]),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_data_df = pd.DataFrame(generated_data_labeled, columns = ['pt1','eta1','m1','pt2','eta2','phi2','m2','tau21j1','tau21j2','mjj','sblabel'])\n",
    "np_sig_df = pd.DataFrame(np_sig_SR_labeled, columns = ['pt1','eta1','m1','pt2','eta2','phi2','m2','tau21j1','tau21j2','mjj','sblabel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               pt1      eta1          m1          pt2      eta2      phi2  \\\n",
       "0      1723.593219 -0.447040  231.848995  1632.559321 -1.270426  3.183638   \n",
       "1      1254.255195  0.586991  356.887180  1236.716592 -1.228783  3.079381   \n",
       "2      1320.811424  0.573153  144.292481  1053.669343 -1.414499  2.826740   \n",
       "3      1535.654695  0.073059  337.541149  1456.906301  1.130604  3.195737   \n",
       "4      1436.127038  1.300800  138.939476   850.611133 -0.725379  3.324772   \n",
       "...            ...       ...         ...          ...       ...       ...   \n",
       "99995  1429.223118 -0.767454   70.913082  1413.135724  0.618603  3.149499   \n",
       "99996  1913.059458 -0.072881   56.876220  1757.349127 -0.582130  3.152659   \n",
       "99997  1404.281612  0.645874  120.390235  1243.818380 -0.865011  3.168753   \n",
       "99998  1705.343780 -0.557433  191.180824  1525.443643  0.300916  3.122352   \n",
       "99999  1349.974343  0.540385   90.210247  1242.249703 -1.244615  3.237765   \n",
       "\n",
       "               m2   tau21j1   tau21j2          mjj  sblabel  \n",
       "0      177.785872  0.485057  0.901190  3518.852295      0.0  \n",
       "1       35.761310  0.309715  0.462774  3539.431885      0.0  \n",
       "2       83.105907  0.764269  0.819507  3532.048584      0.0  \n",
       "3      483.767412  0.778110  0.506943  3374.443848      0.0  \n",
       "4      319.502633  0.484082  0.397005  3441.649170      0.0  \n",
       "...           ...       ...       ...          ...      ...  \n",
       "99995  100.440952  0.839759  0.462240  3481.821777      0.0  \n",
       "99996  185.348648  0.474615  0.296354  3638.103760      0.0  \n",
       "99997  136.292011  0.794827  0.366358  3332.172607      0.0  \n",
       "99998   81.460575  0.257720  0.680162  3378.238037      0.0  \n",
       "99999   98.029207  0.568930  0.646765  3599.288330      0.0  \n",
       "\n",
       "[100000 rows x 11 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pt1</th>\n      <th>eta1</th>\n      <th>m1</th>\n      <th>pt2</th>\n      <th>eta2</th>\n      <th>phi2</th>\n      <th>m2</th>\n      <th>tau21j1</th>\n      <th>tau21j2</th>\n      <th>mjj</th>\n      <th>sblabel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1723.593219</td>\n      <td>-0.447040</td>\n      <td>231.848995</td>\n      <td>1632.559321</td>\n      <td>-1.270426</td>\n      <td>3.183638</td>\n      <td>177.785872</td>\n      <td>0.485057</td>\n      <td>0.901190</td>\n      <td>3518.852295</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1254.255195</td>\n      <td>0.586991</td>\n      <td>356.887180</td>\n      <td>1236.716592</td>\n      <td>-1.228783</td>\n      <td>3.079381</td>\n      <td>35.761310</td>\n      <td>0.309715</td>\n      <td>0.462774</td>\n      <td>3539.431885</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1320.811424</td>\n      <td>0.573153</td>\n      <td>144.292481</td>\n      <td>1053.669343</td>\n      <td>-1.414499</td>\n      <td>2.826740</td>\n      <td>83.105907</td>\n      <td>0.764269</td>\n      <td>0.819507</td>\n      <td>3532.048584</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1535.654695</td>\n      <td>0.073059</td>\n      <td>337.541149</td>\n      <td>1456.906301</td>\n      <td>1.130604</td>\n      <td>3.195737</td>\n      <td>483.767412</td>\n      <td>0.778110</td>\n      <td>0.506943</td>\n      <td>3374.443848</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1436.127038</td>\n      <td>1.300800</td>\n      <td>138.939476</td>\n      <td>850.611133</td>\n      <td>-0.725379</td>\n      <td>3.324772</td>\n      <td>319.502633</td>\n      <td>0.484082</td>\n      <td>0.397005</td>\n      <td>3441.649170</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>99995</th>\n      <td>1429.223118</td>\n      <td>-0.767454</td>\n      <td>70.913082</td>\n      <td>1413.135724</td>\n      <td>0.618603</td>\n      <td>3.149499</td>\n      <td>100.440952</td>\n      <td>0.839759</td>\n      <td>0.462240</td>\n      <td>3481.821777</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>99996</th>\n      <td>1913.059458</td>\n      <td>-0.072881</td>\n      <td>56.876220</td>\n      <td>1757.349127</td>\n      <td>-0.582130</td>\n      <td>3.152659</td>\n      <td>185.348648</td>\n      <td>0.474615</td>\n      <td>0.296354</td>\n      <td>3638.103760</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>99997</th>\n      <td>1404.281612</td>\n      <td>0.645874</td>\n      <td>120.390235</td>\n      <td>1243.818380</td>\n      <td>-0.865011</td>\n      <td>3.168753</td>\n      <td>136.292011</td>\n      <td>0.794827</td>\n      <td>0.366358</td>\n      <td>3332.172607</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>99998</th>\n      <td>1705.343780</td>\n      <td>-0.557433</td>\n      <td>191.180824</td>\n      <td>1525.443643</td>\n      <td>0.300916</td>\n      <td>3.122352</td>\n      <td>81.460575</td>\n      <td>0.257720</td>\n      <td>0.680162</td>\n      <td>3378.238037</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>99999</th>\n      <td>1349.974343</td>\n      <td>0.540385</td>\n      <td>90.210247</td>\n      <td>1242.249703</td>\n      <td>-1.244615</td>\n      <td>3.237765</td>\n      <td>98.029207</td>\n      <td>0.568930</td>\n      <td>0.646765</td>\n      <td>3599.288330</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>100000 rows × 11 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "gen_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                pt1      eta1          m1          pt2      eta2      phi2  \\\n",
       "0       1914.942993  0.369530  105.035004  1583.804443 -0.185737  2.898982   \n",
       "1       1684.598755 -0.523116  159.865997  1647.186768  0.110357  3.141156   \n",
       "2       1789.997070  0.156652   93.665901  1569.509399  0.144243  3.235663   \n",
       "3       1672.631348 -1.015185  116.327003  1568.322998 -0.350886  3.165926   \n",
       "4       1431.694946 -0.700751  513.015991  1099.721313  0.945019  3.245961   \n",
       "...             ...       ...         ...          ...       ...       ...   \n",
       "150591  1678.012939  0.827268  473.352997  1653.355347  0.978250  3.045114   \n",
       "150592  1741.585083 -0.203934   96.165001  1728.791870  0.121508  3.133633   \n",
       "150593  1289.501831  0.922850  115.719002  1153.867065 -0.919407  3.193555   \n",
       "150594  1787.707764  0.032824  508.045013  1381.171143  0.933776  3.163839   \n",
       "150595  1745.240479  0.112269  114.938004  1705.561890 -0.288385  3.096745   \n",
       "\n",
       "                m2   tau21j1   tau21j2          mjj  sblabel  \n",
       "0       461.574005  0.552809  0.121353  3662.211182      1.0  \n",
       "1       514.883972  0.440781  0.299984  3586.710693      1.0  \n",
       "2       475.316986  0.136103  0.135523  3421.777344      1.0  \n",
       "3       561.236023  0.617014  0.294746  3536.982910      1.0  \n",
       "4       108.752998  0.183145  0.456454  3481.573486      1.0  \n",
       "...            ...       ...       ...          ...      ...  \n",
       "150591  111.844002  0.090573  0.308552  3409.779297      1.0  \n",
       "150592  472.475006  0.202213  0.157020  3581.979492      1.0  \n",
       "150593  489.053009  0.271544  0.203001  3622.836914      1.0  \n",
       "150594   91.104897  0.166132  0.588186  3546.809082      1.0  \n",
       "150595  553.737000  0.153972  0.524699  3607.571045      1.0  \n",
       "\n",
       "[150596 rows x 11 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pt1</th>\n      <th>eta1</th>\n      <th>m1</th>\n      <th>pt2</th>\n      <th>eta2</th>\n      <th>phi2</th>\n      <th>m2</th>\n      <th>tau21j1</th>\n      <th>tau21j2</th>\n      <th>mjj</th>\n      <th>sblabel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1914.942993</td>\n      <td>0.369530</td>\n      <td>105.035004</td>\n      <td>1583.804443</td>\n      <td>-0.185737</td>\n      <td>2.898982</td>\n      <td>461.574005</td>\n      <td>0.552809</td>\n      <td>0.121353</td>\n      <td>3662.211182</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1684.598755</td>\n      <td>-0.523116</td>\n      <td>159.865997</td>\n      <td>1647.186768</td>\n      <td>0.110357</td>\n      <td>3.141156</td>\n      <td>514.883972</td>\n      <td>0.440781</td>\n      <td>0.299984</td>\n      <td>3586.710693</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1789.997070</td>\n      <td>0.156652</td>\n      <td>93.665901</td>\n      <td>1569.509399</td>\n      <td>0.144243</td>\n      <td>3.235663</td>\n      <td>475.316986</td>\n      <td>0.136103</td>\n      <td>0.135523</td>\n      <td>3421.777344</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1672.631348</td>\n      <td>-1.015185</td>\n      <td>116.327003</td>\n      <td>1568.322998</td>\n      <td>-0.350886</td>\n      <td>3.165926</td>\n      <td>561.236023</td>\n      <td>0.617014</td>\n      <td>0.294746</td>\n      <td>3536.982910</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1431.694946</td>\n      <td>-0.700751</td>\n      <td>513.015991</td>\n      <td>1099.721313</td>\n      <td>0.945019</td>\n      <td>3.245961</td>\n      <td>108.752998</td>\n      <td>0.183145</td>\n      <td>0.456454</td>\n      <td>3481.573486</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>150591</th>\n      <td>1678.012939</td>\n      <td>0.827268</td>\n      <td>473.352997</td>\n      <td>1653.355347</td>\n      <td>0.978250</td>\n      <td>3.045114</td>\n      <td>111.844002</td>\n      <td>0.090573</td>\n      <td>0.308552</td>\n      <td>3409.779297</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>150592</th>\n      <td>1741.585083</td>\n      <td>-0.203934</td>\n      <td>96.165001</td>\n      <td>1728.791870</td>\n      <td>0.121508</td>\n      <td>3.133633</td>\n      <td>472.475006</td>\n      <td>0.202213</td>\n      <td>0.157020</td>\n      <td>3581.979492</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>150593</th>\n      <td>1289.501831</td>\n      <td>0.922850</td>\n      <td>115.719002</td>\n      <td>1153.867065</td>\n      <td>-0.919407</td>\n      <td>3.193555</td>\n      <td>489.053009</td>\n      <td>0.271544</td>\n      <td>0.203001</td>\n      <td>3622.836914</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>150594</th>\n      <td>1787.707764</td>\n      <td>0.032824</td>\n      <td>508.045013</td>\n      <td>1381.171143</td>\n      <td>0.933776</td>\n      <td>3.163839</td>\n      <td>91.104897</td>\n      <td>0.166132</td>\n      <td>0.588186</td>\n      <td>3546.809082</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>150595</th>\n      <td>1745.240479</td>\n      <td>0.112269</td>\n      <td>114.938004</td>\n      <td>1705.561890</td>\n      <td>-0.288385</td>\n      <td>3.096745</td>\n      <td>553.737000</td>\n      <td>0.153972</td>\n      <td>0.524699</td>\n      <td>3607.571045</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>150596 rows × 11 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "np_sig_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      \n",
    "]\n",
    "def classifier_model():    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(64,input_dim = 4,activation ='relu'))\n",
    "    model.add(layers.Dropout(0.1))\n",
    "    model.add(layers.Dense(64,activation = 'relu'))\n",
    "    model.add(layers.Dropout(0.1))\n",
    "    model.add(layers.Dense(64,activation = 'relu'))\n",
    "    model.add(layers.Dropout(0.1))\n",
    "    model.add(layers.Dense(64,activation = 'relu'))\n",
    "    model.add(layers.Dropout(0.1))\n",
    "    model.add(layers.Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(optimizer='adam',loss='binary_crossentropy',metrics=[METRICS])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 64)                320       \n_________________________________________________________________\ndropout (Dropout)            (None, 64)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 64)                4160      \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 64)                0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 64)                4160      \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 64)                0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 64)                4160      \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 64)                0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 1)                 65        \n=================================================================\nTotal params: 12,865\nTrainable params: 12,865\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier = classifier_model()\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def learningCurveLoss(history):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(history.history['loss'], linewidth=1)\n",
    "    plt.plot(history.history['val_loss'], linewidth=1)\n",
    "    plt.title('Model Loss over Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    #plt.ylim(0,5)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['training sample loss','validation sample loss'])\n",
    "    plt.savefig('5_tag_learning_curve.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    #plt.savefig(\"Learning_Curve\")\n",
    "def plot_roc_curve(y_test, y_test_score):\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_test_score)\n",
    "    auc_value = auc(fpr, tpr)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr,label=' AUC = %.1f%%'%(auc_value*100.))\n",
    "    plt.plot([0, 1], [0, 1], 'k-')\n",
    "\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split background in SR into testing and training. Testing is to inject signals\n",
    "training_idx = np.random.randint(np_bg_SR_labeled.shape[0], size=(int)(np_bg_SR_labeled.shape[0]/2))\n",
    "test_idx = np.random.randint(np_bg_SR_labeled.shape[0], size=(int)(np_bg_SR_labeled.shape[0]/2))\n",
    "training, test = np_bg_SR_labeled[training_idx,:], np_bg_SR_labeled[test_idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(121338, 11)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other half of the bg combined with FULL signal\n",
    "testing_sample = np.concatenate((np_sig_SR_labeled,test),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(271934, 11)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "testing_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = testing_sample[:,[2,6,7,8]]\n",
    "sby_test = testing_sample[:,-1]\n",
    "rfy_test = np.ones([len(x_test),1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(271934, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df = pd.DataFrame(testing_sample, columns = ['pt1','eta1','m1','pt2','eta2','phi2','m2','tau21j1','tau21j2','mjj','sblabel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                pt1      eta1          m1          pt2      eta2      phi2  \\\n",
       "0       1914.942993  0.369530  105.035004  1583.804443 -0.185737  2.898982   \n",
       "1       1684.598755 -0.523116  159.865997  1647.186768  0.110357  3.141156   \n",
       "2       1789.997070  0.156652   93.665901  1569.509399  0.144243  3.235663   \n",
       "3       1672.631348 -1.015185  116.327003  1568.322998 -0.350886  3.165926   \n",
       "4       1431.694946 -0.700751  513.015991  1099.721313  0.945019  3.245961   \n",
       "...             ...       ...         ...          ...       ...       ...   \n",
       "271929  1449.061035  0.949814  427.515015   911.284607 -0.902628  2.916589   \n",
       "271930  1710.843628  0.213326  180.125000  1626.670898 -0.250507  3.055198   \n",
       "271931  1621.522949  0.225366  216.429993  1479.811768 -0.863732  3.083251   \n",
       "271932  1457.715210  1.070146  100.156998  1332.523193 -0.480979  3.156274   \n",
       "271933  1645.761963 -0.184899  215.647995  1444.462891  0.541482  2.967641   \n",
       "\n",
       "                m2   tau21j1   tau21j2          mjj  sblabel  \n",
       "0       461.574005  0.552809  0.121353  3662.211182      1.0  \n",
       "1       514.883972  0.440781  0.299984  3586.710693      1.0  \n",
       "2       475.316986  0.136103  0.135523  3421.777344      1.0  \n",
       "3       561.236023  0.617014  0.294746  3536.982910      1.0  \n",
       "4       108.752998  0.183145  0.456454  3481.573486      1.0  \n",
       "...            ...       ...       ...          ...      ...  \n",
       "271929  123.153000  0.641955  0.656351  3396.115234      0.0  \n",
       "271930  402.979004  0.580612  0.308331  3480.578857      0.0  \n",
       "271931  141.806000  0.607509  0.405151  3587.497314      0.0  \n",
       "271932  134.921997  0.874045  0.716113  3677.205811      0.0  \n",
       "271933  299.884003  0.433886  0.308700  3319.740234      0.0  \n",
       "\n",
       "[271934 rows x 11 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pt1</th>\n      <th>eta1</th>\n      <th>m1</th>\n      <th>pt2</th>\n      <th>eta2</th>\n      <th>phi2</th>\n      <th>m2</th>\n      <th>tau21j1</th>\n      <th>tau21j2</th>\n      <th>mjj</th>\n      <th>sblabel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1914.942993</td>\n      <td>0.369530</td>\n      <td>105.035004</td>\n      <td>1583.804443</td>\n      <td>-0.185737</td>\n      <td>2.898982</td>\n      <td>461.574005</td>\n      <td>0.552809</td>\n      <td>0.121353</td>\n      <td>3662.211182</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1684.598755</td>\n      <td>-0.523116</td>\n      <td>159.865997</td>\n      <td>1647.186768</td>\n      <td>0.110357</td>\n      <td>3.141156</td>\n      <td>514.883972</td>\n      <td>0.440781</td>\n      <td>0.299984</td>\n      <td>3586.710693</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1789.997070</td>\n      <td>0.156652</td>\n      <td>93.665901</td>\n      <td>1569.509399</td>\n      <td>0.144243</td>\n      <td>3.235663</td>\n      <td>475.316986</td>\n      <td>0.136103</td>\n      <td>0.135523</td>\n      <td>3421.777344</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1672.631348</td>\n      <td>-1.015185</td>\n      <td>116.327003</td>\n      <td>1568.322998</td>\n      <td>-0.350886</td>\n      <td>3.165926</td>\n      <td>561.236023</td>\n      <td>0.617014</td>\n      <td>0.294746</td>\n      <td>3536.982910</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1431.694946</td>\n      <td>-0.700751</td>\n      <td>513.015991</td>\n      <td>1099.721313</td>\n      <td>0.945019</td>\n      <td>3.245961</td>\n      <td>108.752998</td>\n      <td>0.183145</td>\n      <td>0.456454</td>\n      <td>3481.573486</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>271929</th>\n      <td>1449.061035</td>\n      <td>0.949814</td>\n      <td>427.515015</td>\n      <td>911.284607</td>\n      <td>-0.902628</td>\n      <td>2.916589</td>\n      <td>123.153000</td>\n      <td>0.641955</td>\n      <td>0.656351</td>\n      <td>3396.115234</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>271930</th>\n      <td>1710.843628</td>\n      <td>0.213326</td>\n      <td>180.125000</td>\n      <td>1626.670898</td>\n      <td>-0.250507</td>\n      <td>3.055198</td>\n      <td>402.979004</td>\n      <td>0.580612</td>\n      <td>0.308331</td>\n      <td>3480.578857</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>271931</th>\n      <td>1621.522949</td>\n      <td>0.225366</td>\n      <td>216.429993</td>\n      <td>1479.811768</td>\n      <td>-0.863732</td>\n      <td>3.083251</td>\n      <td>141.806000</td>\n      <td>0.607509</td>\n      <td>0.405151</td>\n      <td>3587.497314</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>271932</th>\n      <td>1457.715210</td>\n      <td>1.070146</td>\n      <td>100.156998</td>\n      <td>1332.523193</td>\n      <td>-0.480979</td>\n      <td>3.156274</td>\n      <td>134.921997</td>\n      <td>0.874045</td>\n      <td>0.716113</td>\n      <td>3677.205811</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>271933</th>\n      <td>1645.761963</td>\n      <td>-0.184899</td>\n      <td>215.647995</td>\n      <td>1444.462891</td>\n      <td>0.541482</td>\n      <td>2.967641</td>\n      <td>299.884003</td>\n      <td>0.433886</td>\n      <td>0.308700</td>\n      <td>3319.740234</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>271934 rows × 11 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "ts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0.0: 121338, 1.0: 150596}"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "testing_sample[:,10]\n",
    "unique, counts = np.unique(testing_sample[:,10], return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb_ratio = np.logspace(-3,-0.205,5)\n",
    "#sb_ratio = np.linspace(0,0.62,10)\n",
    "mixedsb = []\n",
    "generated_data = []\n",
    "for i in sb_ratio:\n",
    "    sampled_signal = np.random.choice(np_sig_SR_labeled.shape[0], (int)(i * training.shape[0]))\n",
    "    combined = np.concatenate((np_sig_SR_labeled[sampled_signal,:],training), axis =0)\n",
    "    gen = generate_gan(gen_model,combined)\n",
    "    gen2 = generate_gan(gen_model,combined)\n",
    "    gen_data = np.concatenate((gen,gen2),axis=0)\n",
    "    generated_data_labeled  = np.copy(gen_data)\n",
    "    generated_data_labeled = np.append(generated_data_labeled,np.zeros([len(generated_data_labeled),1]),1)\n",
    "    mixedsb.append(sample_data(combined,100000))\n",
    "    generated_data.append(generated_data_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_label_df = pd.DataFrame(mixedsb[4], columns = ['pt1','eta1','m1','pt2','eta2','phi2','m2','tau21j1','tau21j2','mjj','sblabel'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               pt1      eta1          m1          pt2      eta2      phi2  \\\n",
       "0      1254.600098 -0.563055   99.529602   729.849121  1.913283  2.923359   \n",
       "1      1593.913940  1.394608  183.125000  1449.924438  0.378416  3.172369   \n",
       "2      1528.364502 -1.428399  327.631989  1381.010254 -0.299397  3.139722   \n",
       "3      1517.183838 -0.613952  469.332001  1510.345581  0.529763  3.162623   \n",
       "4      1642.973145 -0.073967  118.470001  1625.909058 -0.645671  3.147611   \n",
       "...            ...       ...         ...          ...       ...       ...   \n",
       "99995  1370.128174 -1.430378   44.167599  1129.233765  0.215655  3.128694   \n",
       "99996  1510.500488  0.953385  509.928986  1386.458374 -0.413353  3.195020   \n",
       "99997  1465.834106 -0.492934  155.746002  1245.379150  1.097612  3.145136   \n",
       "99998  1824.210571  0.745977  120.557999  1679.010986  1.091275  3.191449   \n",
       "99999  1465.951294  1.197316  109.332001  1401.281372  0.201884  3.137420   \n",
       "\n",
       "               m2   tau21j1   tau21j2          mjj  sblabel  \n",
       "0       53.182201  0.467114  0.497011  3576.400146      0.0  \n",
       "1      565.619019  0.849766  0.360669  3590.404541      0.0  \n",
       "2      151.988007  0.373334  0.741344  3414.918213      0.0  \n",
       "3       94.184196  0.135307  0.283744  3598.461914      1.0  \n",
       "4      492.571014  0.487898  0.404778  3472.105225      1.0  \n",
       "...           ...       ...       ...          ...      ...  \n",
       "99995  695.244019  0.226933  0.382866  3615.487793      0.0  \n",
       "99996   98.030998  0.361423  0.192808  3658.879395      1.0  \n",
       "99997   81.159103  0.521240  0.436445  3611.982910      0.0  \n",
       "99998  672.534973  0.452797  0.240912  3670.796631      1.0  \n",
       "99999  500.885010  0.557303  0.076772  3338.700439      1.0  \n",
       "\n",
       "[100000 rows x 11 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pt1</th>\n      <th>eta1</th>\n      <th>m1</th>\n      <th>pt2</th>\n      <th>eta2</th>\n      <th>phi2</th>\n      <th>m2</th>\n      <th>tau21j1</th>\n      <th>tau21j2</th>\n      <th>mjj</th>\n      <th>sblabel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1254.600098</td>\n      <td>-0.563055</td>\n      <td>99.529602</td>\n      <td>729.849121</td>\n      <td>1.913283</td>\n      <td>2.923359</td>\n      <td>53.182201</td>\n      <td>0.467114</td>\n      <td>0.497011</td>\n      <td>3576.400146</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1593.913940</td>\n      <td>1.394608</td>\n      <td>183.125000</td>\n      <td>1449.924438</td>\n      <td>0.378416</td>\n      <td>3.172369</td>\n      <td>565.619019</td>\n      <td>0.849766</td>\n      <td>0.360669</td>\n      <td>3590.404541</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1528.364502</td>\n      <td>-1.428399</td>\n      <td>327.631989</td>\n      <td>1381.010254</td>\n      <td>-0.299397</td>\n      <td>3.139722</td>\n      <td>151.988007</td>\n      <td>0.373334</td>\n      <td>0.741344</td>\n      <td>3414.918213</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1517.183838</td>\n      <td>-0.613952</td>\n      <td>469.332001</td>\n      <td>1510.345581</td>\n      <td>0.529763</td>\n      <td>3.162623</td>\n      <td>94.184196</td>\n      <td>0.135307</td>\n      <td>0.283744</td>\n      <td>3598.461914</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1642.973145</td>\n      <td>-0.073967</td>\n      <td>118.470001</td>\n      <td>1625.909058</td>\n      <td>-0.645671</td>\n      <td>3.147611</td>\n      <td>492.571014</td>\n      <td>0.487898</td>\n      <td>0.404778</td>\n      <td>3472.105225</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>99995</th>\n      <td>1370.128174</td>\n      <td>-1.430378</td>\n      <td>44.167599</td>\n      <td>1129.233765</td>\n      <td>0.215655</td>\n      <td>3.128694</td>\n      <td>695.244019</td>\n      <td>0.226933</td>\n      <td>0.382866</td>\n      <td>3615.487793</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>99996</th>\n      <td>1510.500488</td>\n      <td>0.953385</td>\n      <td>509.928986</td>\n      <td>1386.458374</td>\n      <td>-0.413353</td>\n      <td>3.195020</td>\n      <td>98.030998</td>\n      <td>0.361423</td>\n      <td>0.192808</td>\n      <td>3658.879395</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>99997</th>\n      <td>1465.834106</td>\n      <td>-0.492934</td>\n      <td>155.746002</td>\n      <td>1245.379150</td>\n      <td>1.097612</td>\n      <td>3.145136</td>\n      <td>81.159103</td>\n      <td>0.521240</td>\n      <td>0.436445</td>\n      <td>3611.982910</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>99998</th>\n      <td>1824.210571</td>\n      <td>0.745977</td>\n      <td>120.557999</td>\n      <td>1679.010986</td>\n      <td>1.091275</td>\n      <td>3.191449</td>\n      <td>672.534973</td>\n      <td>0.452797</td>\n      <td>0.240912</td>\n      <td>3670.796631</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>99999</th>\n      <td>1465.951294</td>\n      <td>1.197316</td>\n      <td>109.332001</td>\n      <td>1401.281372</td>\n      <td>0.201884</td>\n      <td>3.137420</td>\n      <td>500.885010</td>\n      <td>0.557303</td>\n      <td>0.076772</td>\n      <td>3338.700439</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>100000 rows × 11 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "dataset_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_dataset = []\n",
    "for i in range(len(mixedsb)):\n",
    "    classifier_real = mixedsb[i][:,[2,6,7,8]]\n",
    "    classifier_fake = generated_data[i][:,[2,6,7,8]]\n",
    "    sblabel_real = mixedsb[i][:,10]\n",
    "    sblabel_fake = generated_data[i][:,10]\n",
    "    unscaled_data = np.concatenate((classifier_real,classifier_fake),axis=0)\n",
    "    sblabel = np.concatenate((sblabel_real,sblabel_fake),axis = 0)\n",
    "    scaler = StandardScaler().fit(unscaled_data)\n",
    "    scaled_data = scaler.transform(unscaled_data)\n",
    "    sblabel = sblabel.reshape(len(sblabel),1)\n",
    "    rflabels = np.concatenate((np.ones([len(classifier_real),1]),np.zeros([len(classifier_fake),1])),axis=0)\n",
    "    scaled_data = np.concatenate((scaled_data,sblabel),axis=1)\n",
    "    scaled_dataset.append(np.concatenate((scaled_data,rflabels),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(100000, 11)\n(100000, 11)\n(200000, 6)\n5\n"
     ]
    }
   ],
   "source": [
    "print(generated_data[0].shape)\n",
    "print(mixedsb[0].shape)\n",
    "print(scaled_dataset[0].shape)\n",
    "print(len(scaled_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_dataset_label_df = pd.DataFrame(scaled_dataset[4], columns = ['m1','m2','tau21j1','tau21j2','sblabel','rflabel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              m1        m2   tau21j1   tau21j2  sblabel  rflabel\n",
       "0      -1.246334 -1.368990 -0.409667  1.015285      0.0      1.0\n",
       "1      -1.046928 -0.322792  0.895907  0.507934      0.0      1.0\n",
       "2      -0.702225 -1.167267 -0.729633  1.924482      0.0      1.0\n",
       "3      -0.364218 -1.285280 -1.541762  0.221688      1.0      1.0\n",
       "4      -1.201154 -0.471928 -0.338753  0.672072      1.0      1.0\n",
       "...          ...       ...       ...       ...      ...      ...\n",
       "199995  1.232146  0.966919  1.227899 -0.828604      0.0      0.0\n",
       "199996  1.318266  0.967124  1.189557 -0.828604      0.0      0.0\n",
       "199997  0.771070  0.966813  0.829758 -0.828604      0.0      0.0\n",
       "199998  1.221459  0.967287  1.351200 -0.828604      0.0      0.0\n",
       "199999  0.570684  0.967274 -0.139792 -0.828603      0.0      0.0\n",
       "\n",
       "[200000 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>m1</th>\n      <th>m2</th>\n      <th>tau21j1</th>\n      <th>tau21j2</th>\n      <th>sblabel</th>\n      <th>rflabel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.246334</td>\n      <td>-1.368990</td>\n      <td>-0.409667</td>\n      <td>1.015285</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1.046928</td>\n      <td>-0.322792</td>\n      <td>0.895907</td>\n      <td>0.507934</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.702225</td>\n      <td>-1.167267</td>\n      <td>-0.729633</td>\n      <td>1.924482</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.364218</td>\n      <td>-1.285280</td>\n      <td>-1.541762</td>\n      <td>0.221688</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.201154</td>\n      <td>-0.471928</td>\n      <td>-0.338753</td>\n      <td>0.672072</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>199995</th>\n      <td>1.232146</td>\n      <td>0.966919</td>\n      <td>1.227899</td>\n      <td>-0.828604</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>199996</th>\n      <td>1.318266</td>\n      <td>0.967124</td>\n      <td>1.189557</td>\n      <td>-0.828604</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>199997</th>\n      <td>0.771070</td>\n      <td>0.966813</td>\n      <td>0.829758</td>\n      <td>-0.828604</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>199998</th>\n      <td>1.221459</td>\n      <td>0.967287</td>\n      <td>1.351200</td>\n      <td>-0.828604</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>199999</th>\n      <td>0.570684</td>\n      <td>0.967274</td>\n      <td>-0.139792</td>\n      <td>-0.828603</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>200000 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "scaled_dataset_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001D0A62BD400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001D0A62BD400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0092 - tp: 79761.0000 - fp: 2.0000 - tn: 79991.0000 - fn: 246.0000 - accuracy: 0.9984 - precision: 1.0000 - recall: 0.9969 - auc: 1.0000WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001D2373D9AE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001D2373D9AE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0092 - tp: 79761.0000 - fp: 2.0000 - tn: 79991.0000 - fn: 246.0000 - accuracy: 0.9984 - precision: 1.0000 - recall: 0.9969 - auc: 1.0000 - val_loss: 1.4560e-05 - val_tp: 19993.0000 - val_fp: 0.0000e+00 - val_tn: 20007.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 2/10\n",
      " 619/1250 [=============>................] - ETA: 4s - loss: 1.4713e-04 - tp: 39666.0000 - fp: 2.0000 - tn: 39563.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 0.9999 - recall: 1.0000 - auc: 1.0000"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-40e2f9dc52e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msby_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msby_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaled_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscaled_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mlearningCurveLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1103\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    438\u001b[0m     \"\"\"\n\u001b[0;32m    439\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    340\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_supports_tf_logs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m         \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    962\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1014\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1016\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1017\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 537\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    531\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m     \"\"\"\n\u001b[0;32m   1062\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1064\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1027\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ypred4c = []\n",
    "fp_4c, tp_4c,th_4c= [],[],[]\n",
    "auc_list_4c = []\n",
    "for i in range(len(mixedsb)): \n",
    "    x_train,x_val,y_train,y_val = train_test_split(scaled_dataset[i][:,0:4],scaled_dataset[i][:,-1], test_size = 0.2, random_state=42)\n",
    "    _,_,sby_train,sby_val = train_test_split(scaled_dataset[i][:,0:4],scaled_dataset[i][:,-2], test_size = 0.2, random_state=42)\n",
    "    classifier = classifier_model()\n",
    "    history = classifier.fit(x_train, y_train, epochs=10, batch_size=128,validation_data=(x_val,y_val))\n",
    "    learningCurveLoss(history)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    ypred4c.append(y_pred)\n",
    "    fpr, tpr, thresholds = roc_curve(sby_test, y_pred)\n",
    "    auc_value = auc(fpr,tpr)\n",
    "    auc_list_4c.append(auc_value)\n",
    "    fp_4c.append(fpr)\n",
    "    tp_4c.append(tpr)\n",
    "    th_4c.append(thresholds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}